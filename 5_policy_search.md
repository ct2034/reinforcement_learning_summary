<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

## Outline
* auto-gen TOC:
{:toc}

## Intro
* Policy Search uses
    - exploration
    - evaluation
    - updates
* based on experience data
* not model-based
* not learning a value func first

* value based solution inefficient for large or high-dimensional spaces

<iframe width="560" height="315" src="https://www.youtube.com/embed/bJMib3EPwAE" frameborder="0" allowfullscreen></iframe>

## Difference between Policy Search and Value-based RL


## Plain Policy Gradient

## Likelihood Ratio Gradient

## REINFORCE

## G(PO)MDP

## Gauss-Newton 
* second-order policy gradient

## Natural Gradient-Actor-Critic
## Natural Actor-Critic
